# Ściągawka: Algorytmy Uczenia Maszynowego

| Algorytm              | Typ          | Przypadek użycia              | Kluczowa logika / wzór                           | Założenia                  | Zalety                          | Wady                              | Nie używać, gdy...                               | Przykład z życia codziennego        |
|-----------------------|--------------|-------------------------------|--------------------------------------------------|----------------------------|----------------------------------|-----------------------------------|--------------------------------------------------|-------------------------------------|
| Regresja liniowa      | Nadzorowane  | Predykcja wartości ciągłych   | Y = b0 + b1X + ...                               | Liniowość, niezależność    | Prosty, interpretowalny, szybki | Wrażliwy na odstające dane        | Dane nieliniowe, silna korelacja zmiennych      | Prognozowanie cen mieszkań          |
| Regresja logistyczna  | Nadzorowane  | Klasyfikacja binarna          | P = 1 / (1 + e^-(b0 + b1X + ...))               | Logit, liniowość log-odds | Probabilistyczna, interpretowalna| Słaba przy danych nieliniowych    | Silna nieliniowość danych                      | Wykrywanie spamu                     |
| Drzewo decyzyjne      | Nadzorowane  | Klasyfikacja / regresja       | Rekurencyjny podział                            | Brak                      | Proste, łatwe do zrozumienia     | Niestabilne, podatne na overfitting| Mało danych, skomplikowane zależności           | Predykcja kredytowa                 |
| Random Forest         | Nadzorowane  | Zwiększenie dokładności       | Bagging + agregacja                            | Niezależność drzew         | Wysoka dokładność                | Wolniejszy, mniej interpretowalny | Potrzebna interpretowalność modelu              | Wykrywanie oszustw                  |
| Gradient Boosting     | Nadzorowane  | Modelowanie high-performance  | Kolejne modele uczą się na błędach poprzednich  | Kolejność danych ważna     | Najwyższa dokładność             | Overfitting, wolniejszy           | Gdy interpretowalność kluczowa                  | Scoring kredytowy                   |
| SVM                   | Nadzorowane  | Klasyfikacja                 | Maksymalizacja marginesu separacji              | Separowalność              | Dobry w dużych wymiarach         | Wolny przy dużych zbiorach         | Duże zbiory danych                             | Rozpoznawanie twarzy                |
| KNN                   | Nadzorowane  | Klasyfikacja „few-shot”       | Głosowanie większościowe w sąsiedztwie          | Skalowanie cech            | Prosty, brak treningu            | Wolny, wrażliwy na hałas           | Dużo cech, zaszumione dane                     | Systemy rekomendacyjne              |
| Naive Bayes           | Nadzorowane  | Klasyfikacja tekstu           | Niezależność cech, tw. Bayesa                   | Cechy niezależne           | Szybki, dobry do tekstu          | Założenia często nienaturalne      | Silna zależność między cechami                 | Analiza sentymentu                  |
| K-Means               | Nienadzorowane| Segmentacja klientów          | Minimalizacja odległości w klastrach            | Kulistość klastrów         | Szybki, łatwy do zrozumienia     | Wymaga podania liczby klastrów     | Niekuliste klastry, różne rozmiary              | Segmentacja klientów                |
| Klasteryzacja hier.   | Nienadzorowane| Struktura danych              | Dendrogram, podziały zagnieżdżone               | Metryka odległości         | Wizualizacja, brak K             | Wydajność przy dużych zbiorach     | Bardzo duże zbiory danych                      | Analiza ekspresji genów             |
| PCA                   | Redukcja wymiaru| Redukcja liczby cech        | Macierz wartości własnych                      | Duża wariancja ważna       | Odszumianie, wizualizacja        | Trudna interpretacja              | Gdy każda cecha istotna                        | Kompresja obrazu                    |
| Sieci neuronowe (MLP) | Nadzorowane  | Wzorce nieliniowe             | Wagi + funkcje aktywacji                        | Dużo danych                 | Bardzo wydajne                   | Black-box, potrzeba danych         | Mało danych, interpretowalność                 | Klasyfikacja obrazów                |
| CNN                   | Nadzorowane  | Obraz/wideo                  | Sploty + pooling                               | Dane siatkowe              | Super do obrazów/wideo           | Duże zapotrzebowanie na zasoby     | Przetwarzanie sekwencji                      | Autonomiczne pojazdy                |
| RNN                   | Nadzorowane  | Dane sekwencyjne              | Sprzężenie zwrotne                             | Kolejność ważna            | Dobre do tekstu                  | Zanikanie gradientu                | Długie sekwencje                              | Prognozowanie giełdy                |
| Transformer (BERT, GPT)| Nadz./Samo. | NLP, czat, tłumaczenia        | Mechanizm uwagi + pozycje                      | Duże dane                   | Długi kontekst, szybki           | Duże koszty obliczeniowe           | Małe projekty                              | ChatGPT, tłumaczenia                 |
| Autoenkodery          | Nienadzorowane| Detekcja anomalii, kompresja | Encoder-decoder                                | Sieć symetryczna           | Dobre odszumianie                | Może naduczyć, czarna skrzynka     | Brak potrzeby kompresji                      | Wykrywanie oszustw                  |
| DBSCAN                | Nienadzorowane| Klastrowanie nieregularne    | Gęstość punktów                                | Gęstość klastrów           | Tolerancja szumu, elastyczność   | Słaby przy różnej gęstości         | Gęstość zmienna, wysokowymiarowe dane         | Klasteryzacja geoprzestrzenna       |
| GMM (Mixture Gaussowska)| Nienadzorowane  | Klasteryzacja probabilistyczna  | Kombinacja wielu rozkładów Gaussa                | Dane zbliżone do Gaussa    | Modeluje nakładające się klastry | Wrażliwy na inicjalizację           | Gdy dane nie mają rozkładów normalnych          | Segmentacja obrazów, bioinformatyka |

---

Stworzono przez **Tymoteusz Miller**  
Repozytorium zawiera osobne tutoriale dla każdego algorytmu – zapraszamy do folderów!
