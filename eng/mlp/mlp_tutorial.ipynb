{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b469ee90",
   "metadata": {},
   "source": [
    "# Multi-Layer Perceptron (MLP): Advanced Tutorial\n",
    "\n",
    "This notebook demonstrates the use of MLPs (fully connected feed-forward neural networks) for classification using synthetic and real-world data.\n",
    "We cover:\n",
    "- Theory and architecture\n",
    "- Using `sklearn.neural_network.MLPClassifier`\n",
    "- Training, tuning, and evaluation\n",
    "- Real-world dataset: digits recognition\n",
    "- Activation functions and hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed03b8b",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2033c3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import make_moons, load_digits\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set(style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23b95ad",
   "metadata": {},
   "source": [
    "## 2. What is an MLP?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53daa71e",
   "metadata": {},
   "source": [
    "A Multi-Layer Perceptron (MLP) is a type of feedforward artificial neural network that consists of:\n",
    "- An input layer\n",
    "- One or more hidden layers (fully connected)\n",
    "- An output layer\n",
    "\n",
    "Each neuron applies a weighted sum followed by an **activation function** such as ReLU or tanh.  \n",
    "MLPs can model complex, nonlinear decision boundaries.\n",
    "\n",
    "We use `MLPClassifier` from `sklearn.neural_network` for classification tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f62a215",
   "metadata": {},
   "source": [
    "## 3. Synthetic Data: Two-Class Moons Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5dcb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_moons(n_samples=1000, noise=0.2, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=X[:, 0], y=X[:, 1], hue=y, palette=\"coolwarm\")\n",
    "plt.title(\"Synthetic Moon-Shaped Dataset\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bda01f",
   "metadata": {},
   "source": [
    "## 4. Train an MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500e1591",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', max_iter=1000, random_state=42)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "y_pred = mlp.predict(X_test_scaled)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "ConfusionMatrixDisplay.from_estimator(mlp, X_test_scaled, y_test, cmap='Blues')\n",
    "plt.title(\"Confusion Matrix - MLP on Moon Data\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711517dc",
   "metadata": {},
   "source": [
    "## 5. Real Dataset: Digits Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34efaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "X_digits = digits.data\n",
    "y_digits = digits.target\n",
    "\n",
    "X_train_d, X_test_d, y_train_d, y_test_d = train_test_split(X_digits, y_digits, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler_d = StandardScaler()\n",
    "X_train_d_scaled = scaler_d.fit_transform(X_train_d)\n",
    "X_test_d_scaled = scaler_d.transform(X_test_d)\n",
    "\n",
    "mlp_digits = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', max_iter=1000, random_state=42)\n",
    "mlp_digits.fit(X_train_d_scaled, y_train_d)\n",
    "\n",
    "y_pred_d = mlp_digits.predict(X_test_d_scaled)\n",
    "print(classification_report(y_test_d, y_pred_d))\n",
    "ConfusionMatrixDisplay.from_estimator(mlp_digits, X_test_d_scaled, y_test_d, cmap='Purples')\n",
    "plt.title(\"Confusion Matrix - Digits MLP\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5ce055",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a6595a",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'alpha': [0.0001, 0.001],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(MLPClassifier(max_iter=1000, random_state=42), param_grid, cv=3, n_jobs=-1)\n",
    "grid_search.fit(X_train_d_scaled, y_train_d)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-val score:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105797b7",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "- MLPs can model complex patterns via hidden layers and activation functions\n",
    "- Proper scaling is essential for convergence\n",
    "- GridSearchCV helps tune depth, width, activation\n",
    "- MLPs are flexible and widely used in structured data classification"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
