# Decision Trees

[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/TyMill/ml-starter-kit/blob/main/eng/decision_tree/decision_tree_tutorial.ipynb)
[![Try on Kaggle](https://img.shields.io/badge/Open%20in-Kaggle-blue)](https://www.kaggle.com/code)
[![JupyterLite](https://img.shields.io/badge/Try%20it-JupyterLite-orange)](https://jupyterlite.github.io/demo)

**Decision Trees** are intuitive and powerful models used for classification and regression.  
They mimic human decision-making with a flowchart-like structure, making them highly interpretable.

---

## ğŸŒ³ What is a Decision Tree?

- **Internal nodes**: decision rules on features  
- **Branches**: outcomes of the decision  
- **Leaves**: final predictions or class labels  

The model splits data recursively to reduce impurity (e.g., Gini or entropy).

---

## âœ… Advantages

- Easy to interpret and visualize  
- Handles both numerical and categorical data  
- Requires minimal preprocessing  
- Non-linear boundaries without transformations

## âŒ Disadvantages

- Can overfit (especially with deep trees)  
- Sensitive to small data changes  
- Greedy splitting doesnâ€™t guarantee global optimum

---

## ğŸ§ª Whatâ€™s Inside the Tutorial

- ğŸŒ¸ Classification on the Iris dataset  
- ğŸŒ³ Training a DecisionTreeClassifier (`sklearn`)  
- ğŸ“Š Visualizing the tree and extracting rules  
- ğŸ§  Evaluation with confusion matrix & classification report  
- ğŸ”„ Cross-validation and effect of tree depth

ğŸ“˜ Notebook: [`decision_tree_tutorial.ipynb`](./decision_tree_tutorial.ipynb)

---

## ğŸ“‚ File Structure

- `decision_tree_tutorial.ipynb` â€“ Full decision tree pipeline  
- `README.md` â€“ This file  
- `references.md` â€“ Further resources

---

## ğŸ“š Recommended Reading

- [scikit-learn: Decision Trees](https://scikit-learn.org/stable/modules/tree.html)  
- [Wikipedia: Decision Tree Learning](https://en.wikipedia.org/wiki/Decision_tree_learning)  
- [ML Cheatsheet â€“ Decision Trees](https://ml-cheatsheet.readthedocs.io/en/latest/decision_trees.html)

---

## ğŸš€ Try It Yourself

- Tune `max_depth`, `min_samples_split`, `criterion`  
- Try `DecisionTreeRegressor` for regression tasks  
- Use `export_text()` to extract explainable rules  
- Compare with RandomForest or GradientBoosting

---

Created with ğŸŒ¿ by **Tymoteusz Miller** â€” part of the [ML Starter Kit](https://github.com/TyMill/ml-starter-kit)
