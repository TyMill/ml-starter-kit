# Autoencoder (AE)

[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/TyMill/ml-starter-kit/blob/main/eng/autoencoder/autoencoder_tutorial.ipynb)
[![Try on Kaggle](https://img.shields.io/badge/Open%20in-Kaggle-blue)](https://www.kaggle.com/code)
[![JupyterLite](https://img.shields.io/badge/Try%20it-JupyterLite-orange)](https://jupyterlite.github.io/demo)

An **Autoencoder (AE)** is an unsupervised neural network that learns a compressed (latent) representation of input data.  
It's trained to **reconstruct its own input**, making it powerful for dimensionality reduction, denoising, and anomaly detection.

---

## ğŸ” What is an Autoencoder?

Autoencoders are composed of two main parts:

- **Encoder**: compresses the input to a latent space  
- **Decoder**: reconstructs the input from the latent representation  

The network is trained by minimizing reconstruction loss, usually Mean Squared Error (MSE).

---

## ğŸ§  When to Use

- Dimensionality reduction (nonlinear PCA alternative)
- Denoising and feature learning
- Pretraining for deep networks
- Anomaly detection
- Image or signal reconstruction

---

## âœ… Advantages

- Learns complex nonlinear embeddings
- Unsupervised learning â€“ no labels required
- Flexible architecture (deep, convolutional, variational, etc.)
- Visualization and interpretation of latent features

## âŒ Disadvantages

- Requires careful tuning and architecture design
- May memorize input without generalizing
- Can be outperformed by simpler models if poorly regularized

---

## ğŸ§ª Whatâ€™s Inside the Tutorial

This notebook includes:
- ğŸ§± Fully connected autoencoder in Keras
- ğŸ” Visualization of 2D latent space vs PCA
- ğŸ§  Digits dataset for reconstruction and evaluation
- ğŸš¨ Anomaly detection via reconstruction error
- ğŸ“‰ Loss curves and error distribution analysis

ğŸ“˜ Notebook: [`autoencoder_tutorial.ipynb`](./autoencoder_tutorial.ipynb)

---

## ğŸ“‚ File Structure

- `autoencoder_tutorial.ipynb` â€“ Full implementation and experiments
- `README.md` â€“ This file
- `references.md` â€“ External resources

---

## ğŸ“š Recommended Reading

- [Keras Autoencoder Guide](https://keras.io/examples/autoencoder/)
- [Wikipedia: Autoencoder](https://en.wikipedia.org/wiki/Autoencoder)
- [scikit-learn: PCA (comparison)](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)

---

## âœ¨ Example Visualization

<p align="center">
  <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/3/38/Autoencoder_structure.png/512px-Autoencoder_structure.png" width="500"/>
</p>

---

## ğŸ§  Try It Yourself

- Try convolutional autoencoders on image data
- Replace activation functions (ReLU, tanh, leaky ReLU)
- Use `encoder.predict(X)` for compressed features
- Visualize anomaly scores in a business use case

---

Created with ğŸ§¬ by **Tymoteusz Miller** â€” part of the [ML Starter Kit](https://github.com/TyMill/ml-starter-kit)
