{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96764986",
   "metadata": {},
   "source": [
    "# Autoencoder: Advanced Tutorial\n",
    "\n",
    "In this notebook, we build and analyze autoencoders using real data.\n",
    "We cover:\n",
    "- Theory: what are autoencoders?\n",
    "- Dense autoencoder with Keras\n",
    "- Dimensionality reduction vs PCA\n",
    "- Image reconstruction\n",
    "- Anomaly detection with autoencoders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2d35e2",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eea57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db24fa00",
   "metadata": {},
   "source": [
    "## 2. What is an Autoencoder?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ab962d",
   "metadata": {},
   "source": [
    "An **Autoencoder (AE)** is a type of neural network used to learn compressed representations of data (encoding), typically for the purposes of:\n",
    "- Dimensionality reduction\n",
    "- Denoising\n",
    "- Anomaly detection\n",
    "\n",
    "It consists of two parts:\n",
    "- **Encoder**: Compresses the input\n",
    "- **Decoder**: Reconstructs the input from compressed form\n",
    "\n",
    "The model is trained to minimize reconstruction error (e.g., MSE loss).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0432bd29",
   "metadata": {},
   "source": [
    "## 3. Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b395d1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "X = digits.data / 16.0  # normalize\n",
    "y = digits.target\n",
    "\n",
    "X_train, X_test, _, _ = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Input shape:\", X_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555ef856",
   "metadata": {},
   "source": [
    "## 4. Build a Dense Autoencoder with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c421dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "encoding_dim = 16\n",
    "\n",
    "# Encoder\n",
    "input_layer = layers.Input(shape=(input_dim,))\n",
    "encoded = layers.Dense(64, activation='relu')(input_layer)\n",
    "encoded = layers.Dense(encoding_dim, activation='relu')(encoded)\n",
    "\n",
    "# Decoder\n",
    "decoded = layers.Dense(64, activation='relu')(encoded)\n",
    "decoded = layers.Dense(input_dim, activation='sigmoid')(decoded)\n",
    "\n",
    "# Autoencoder model\n",
    "autoencoder = models.Model(inputs=input_layer, outputs=decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b244ab2a",
   "metadata": {},
   "source": [
    "## 5. Train the Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1884fba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = autoencoder.fit(X_train, X_train,\n",
    "                          epochs=50,\n",
    "                          batch_size=32,\n",
    "                          shuffle=True,\n",
    "                          validation_data=(X_test, X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d80a86f",
   "metadata": {},
   "source": [
    "## 6. Plot Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7670909",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title(\"Training Loss Curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6236def",
   "metadata": {},
   "source": [
    "## 7. Compare PCA vs Autoencoder Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b5aee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = models.Model(inputs=input_layer, outputs=encoded)\n",
    "X_encoded = encoder.predict(X_test)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_test)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_encoded[:, 0], X_encoded[:, 1], c=y[:len(X_encoded)], cmap='tab10', s=15)\n",
    "plt.title(\"Autoencoder Embedding (2D)\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y[:len(X_pca)], cmap='tab10', s=15)\n",
    "plt.title(\"PCA Embedding (2D)\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218c5e3d",
   "metadata": {},
   "source": [
    "## 8. Visualize Reconstruction Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb973fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_decoded = autoencoder.predict(X_test)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(X_test[i].reshape(8, 8), cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    # reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(X_test_decoded[i].reshape(8, 8), cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.suptitle(\"Original vs Reconstructed Images\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265aa169",
   "metadata": {},
   "source": [
    "## 9. Anomaly Detection: Inject Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4ea291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a noisy version of X_test\n",
    "X_noisy = X_test.copy()\n",
    "X_noisy[:10] += np.random.normal(0, 1.5, X_noisy[:10].shape)\n",
    "\n",
    "# Predict and measure error\n",
    "X_decoded = autoencoder.predict(X_noisy)\n",
    "mse = np.mean((X_noisy - X_decoded) ** 2, axis=1)\n",
    "\n",
    "plt.hist(mse, bins=30)\n",
    "plt.title(\"Reconstruction Error (MSE)\")\n",
    "plt.xlabel(\"Error\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.axvline(np.mean(mse[:10]), color='red', linestyle='--', label=\"Anomalies\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359f97a7",
   "metadata": {},
   "source": [
    "## 10. Summary\n",
    "\n",
    "- Autoencoders compress and reconstruct data\n",
    "- Great for dimensionality reduction and anomaly detection\n",
    "- Can be extended to convolutional and variational autoencoders\n",
    "- Compare embeddings with PCA, visualize reconstructions, and track reconstruction error"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
